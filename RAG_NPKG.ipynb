{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25448996-9b8b-402a-b38d-9d7f981e6925",
   "metadata": {},
   "source": [
    "# Load enviroment and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d91de3a-30ed-487f-bdfc-425f151fdb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source activate /ix/rboyce/iod4/envs/FM\n",
    "!export HF_HOME=\"/ix/rboyce/shared/cache/huggingface/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a872f6-5354-4366-98e8-850f3b52e66e",
   "metadata": {},
   "source": [
    "## Install or update models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686e3c5d-b3d1-43ec-a6e5-f94642e1978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install accelerate\n",
    "# !huggingface-cli download meta-llama/Meta-Llama-3-8B-Instruct --include \"original/*\" --local-dir meta-llama/Meta-Llama-3-8B-Instruct\n",
    "# !pip install --upgrade transformers optimum optimum-intel\n",
    "# !pip install --upgrade torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ef2558d-9bd6-4a45-84e7-cecf77fd233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4562b6-699d-414a-8a41-fca5cc862742",
   "metadata": {},
   "source": [
    "# Model Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5040c99f-5e9d-46cb-8525-cfe50ab19632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas:\n",
    "# How can we prompt the models to mention how recent the information cited is?\n",
    "# How can we accurately ask the model to convey if the results can be extrapolated between NPs?\n",
    "# Can we craft the LLM's role in a way that represents the intersection between the three personas? (clinical pharmacists, drug-drug interaction researchers, and drug interaction compendium editors)\n",
    "\n",
    "# Alternative queries:\n",
    "# \"What are the potential mechanisms for the interaction between cranberry natural products and the drug warfarin as detected by an increase in their International Normalized Ratio (INR) blood test?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c9e071-0e4c-40de-9d70-b473dce6c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_header = \"### Instructions ###\\n\\n\"\n",
    "context_header = \"### Context ###\\n\\n\"\n",
    "context_instruction = \"\\nInclude relevant items from the following information in your synthesis:\\n\"\n",
    "query_header = \"### Query ###\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a0308a9-f2e8-4014-a763-e4c336ff7e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruction_header + prompt + query_header + queries[0].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55eda531-5580-4ef6-9a93-68951d915d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =  \"\"\n",
    "with open('./instruction_prompt.txt', 'r') as f:\n",
    "    prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d35c3670-20bd-422b-acd6-6fe713876159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "137142da-a518-497b-b93b-0ffdbbd19030",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the potential mechanisms that cause an interaction between {NP} products and {Drug} that may cause {AE}?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eec695a2-d797-4b81-bef0-004ada898e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = PromptTemplate.from_template(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b184016-8bdf-4f99-9409-fbd8862380e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = pd.read_csv(\"./Data/CaseStudyMappings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08ee1589-95af-4915-a9f8-8fbc15fa6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []\n",
    "for row in mappings[[\"NP\", \"Drug\", \"AE\"]].iterrows():\n",
    "    queries.append(query_template.invoke(row[1].to_dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480717b3-e2e4-40b6-a2c2-b99edf829374",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39678e8b-40e2-4452-a706-5c38829a07e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Important things to target with the Spoke Approach.\n",
    "\n",
    "1. Combining generated and retrieved knowledge.\n",
    "2. Improve the relevance of the context by improving the prompt. \"prompt aware context\"\n",
    "  - Alternative names for the NP.\n",
    "  - Alternative names for the drug.\n",
    "  - Alternative concepts for the AE.\n",
    "  - Mesh Terms for each, if available.\n",
    "3. Retrieve relevant context from NPKG.\n",
    "4. Retrieve relevant EMA monographs.\n",
    "5. Retrieve relevant Stockley's monographs.\n",
    "6. Merge or Synthesize all these into a single context.\n",
    "\n",
    "## Challenges:\n",
    "1. Alternative names could be gathered from staging_vocabulary (\"napdi repo db\")\n",
    "2. Splitting and merging all the information from the different sources.\n",
    "3. Consider OntoGPT ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170520ec-4d23-41b8-953c-19ab54a7b19f",
   "metadata": {},
   "source": [
    "# Spokelike from NPKG, EMA, & Stockleys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f4dd68-be8b-4f3c-a8fe-54e7e62b5eb7",
   "metadata": {},
   "source": [
    "## Loading Documents for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdb58339-0183-477c-b3a6-c75bdbb9e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader, CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fa368c8-ea4e-4d9a-92b0-8011b672b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"./Clean_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db7d596-ad42-4d31-ad4e-a7a28dc346f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_loader_kwargs={'autodetect_encoding': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "067ca63f-00c5-4cf6-9154-a0b3e28b5f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(data_folder, glob=\"**/*.txt\", show_progress=True, use_multithreading=True, loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b893755-136f-4d4d-8154-95176ee22169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 260/268 [00:00<00:00, 2147.13it/s]\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9496645a-007a-4c2c-9334-736fbf5a425a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "493cf4c3-4dfd-4154-b219-d611419f3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.cleaners.core import clean, replace_unicode_quotes, group_broken_paragraphs, clean_non_ascii_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2da58ddf-f6d3-4bfa-92d2-795df3af6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(docs)):\n",
    "    docs[i].page_content = docs[i].page_content.replace(\"Unnamed: 1 Unnamed: 2 \", \"\")\n",
    "    docs[i].page_content = clean(docs[i].page_content, extra_whitespace=True)\n",
    "    docs[i].page_content = group_broken_paragraphs(docs[i].page_content)\n",
    "    docs[i].page_content = replace_unicode_quotes(docs[i].page_content)\n",
    "    # docs[i].page_content = clean_non_ascii_chars(docs[i].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c6cf3f6-edb1-468a-b78f-e73aacb13165",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_loader = CSVLoader(file_path=data_folder+'ema.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "700ae66d-c591-4ac8-b3d3-31f6706e6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csv_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "335154ab-5087-4544-a24b-4a0b189e663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bb8a897-ac21-490d-856b-c1a1631cd6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "838"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed5e724-7640-485b-802d-d34bb3beb31e",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea6da60-77a0-4776-9cfa-ff4c6a964a47",
   "metadata": {},
   "source": [
    "## Create Vector Store with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5800302-5b28-4fa1-92ee-7e2e262cb064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing docs\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "583f6598-b9ac-49cd-8291-cef2b9ce066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "163985bc-8a07-4fc3-a232-d3608bb77d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ed6b0f7-e68d-4a11-ac97-5c9135b7731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "#     os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "505f21d1-a387-4af2-89b3-a904d022f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_PERSONAL_API_KEY\", default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e10fcec5-37c7-4efc-a5c4-c6fe43e1beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "934de6c9-44b5-400c-aa93-d3c445e41ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66a38fa3-38ac-49cc-8fa7-a07e89de03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"Relationship between a natural product a drug and a adverse event.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ed4cfb2-7be4-48fc-982a-3f79b7815a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81da3257-ef95-4f8c-b0cf-8767262fa8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbafed64-1886-4d8d-a69f-30370b2fdaae",
   "metadata": {},
   "source": [
    "## Create retreiver from Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "646db2db-6b27-42f8-85bf-b959089bbc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 25, 'fetch_k': 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a661bb5-7d2d-410b-9adb-485ed490434e",
   "metadata": {},
   "source": [
    "## Include MultiQuery Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00d1495f-74f7-4a00-a3a2-952c9728fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97bffa48-2b9f-4d13-b6ea-7dd9684d1cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging for the queries\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0f793fd-fecc-4234-a89e-381072c097ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",temperature=1)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=db_retriever, \n",
    "    llm=llm,\n",
    "    include_original=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "177762bb-6b75-4e82-aad2-6bb044ffa80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''.join([prompt, '\\n', queries[0].text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82017eb6-374b-43ef-92d2-4c5903222f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever_from_llm.generate_queries(''.join([prompt, '\\n', queries[0].text]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b68ea4c4-1c29-42ac-aff1-4457de4612c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_docs = retriever_from_llm.invoke(''.join([prompt, '\\n', queries[0].text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "206755f9-674e-441e-89cc-c5d29047cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eba56620-0f2a-47a9-8c74-d851a8115ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty_print_docs(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c06366c4-e62c-4e6d-a8ea-acf9697bb1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet  cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18120307-9561-46d6-b560-7f973d0b1ad8",
   "metadata": {},
   "source": [
    "## Split Large Documents, Filter Irrelevantt Sections, & Rerank Revelant Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dce7c3f4-256b-417d-9960-5ad039b80cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "# from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "# from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ab5b203-ba62-4b4a-bc20-3a549048ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['COHERE_API_KEY'] = os.environ.get(\"COHERE_API_KEY\", default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "95f02f4f-69eb-418a-98d6-352077c7ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = CharacterTextSplitter(chunk_size=3500, chunk_overlap=0, separator=\". \")\n",
    "relevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.01, k = 15) # doc 2 query\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings, similarity_threshold=0.98, k = 10) # doc 2 doc\n",
    "reranker = CohereRerank(top_n = 8)\n",
    "# llm_compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20348f0e-1fa9-45d1-be3c-d96ca686ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers= [splitter, relevant_filter, redundant_filter, reranker]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4bad3f35-1dc6-4628-808b-aae287f0517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor, base_retriever=retriever_from_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5d4de0df-1a71-4aeb-a2af-c69b12b405aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the potential mechanisms that cause an interaction between Ginger products and Tacrolimus that may cause Nephrotoxicity?'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[6].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "936e793b-e17c-4292-914f-e9b91616c8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['What are the possible ways in which Ginger products may interact with Tacrolimus to lead to kidney toxicity?', 'How might Ginger products contribute to nephrotoxic effects when taken alongside Tacrolimus?', 'What mechanisms could explain the interaction between Ginger products and Tacrolimus that results in increased risk of kidney damage?']\n"
     ]
    }
   ],
   "source": [
    "compressed_docs = compression_retriever.invoke(queries[6].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f28f30e9-2976-40fb-9c34-6b0c6a8f5b2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "The Natural Product gingerol directly negatively regulates activity of the Enzyme or Transporter ATP-dependent translocase ABCB1 (human). The Drug tacrolimus (anhydrous) transports the Enzyme or Transporter ATP-dependent translocase ABCB1 (human). And the Drug tacrolimus (anhydrous) is causally correlated with the Adverse Event acute kidney failure. Natural Product Ontology Identifier: http://napdi.org/napdi_srs_imports:zingiber_officinale Natural Product or Constituent Ontology Identifier: http://purl.obolibrary.org/obo/CHEBI_10136 Process Ontology Identifier: http://purl.obolibrary.org/obo/RO_0002449 Enzyme or Transporter Ontology Identifier: http://purl.obolibrary.org/obo/PR_P08183 Process or Pathway Ontology Identifier: http://purl.obolibrary.org/obo/RO_0002020 Drug Ontology Identifier: http://purl.obolibrary.org/obo/CHEBI_61049 Causal Relation Ontology Identifier: http://purl.obolibrary.org/obo/RO_0002610 Adverse Event Ontology Identifier: http://purl.obolibrary.org/obo/MONDO_0002492\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "The Natural Product gingerol directly negatively regulates activity of the Enzyme or Transporter cytochrome P450 3A4 (human). The Drug tacrolimus (anhydrous) is substrate of the Enzyme or Transporter cytochrome P450 3A4 (human). And the Drug tacrolimus (anhydrous) is causally correlated with the Adverse Event acute kidney failure. Natural Product Ontology Identifier: http://napdi.org/napdi_srs_imports:zingiber_officinale Natural Product or Constituent Ontology Identifier: http://purl.obolibrary.org/obo/CHEBI_10136 Process Ontology Identifier: http://purl.obolibrary.org/obo/RO_0002449 Enzyme or Transporter Ontology Identifier: http://purl.obolibrary.org/obo/PR_P08684 Process or Pathway Ontology Identifier: http://purl.obolibrary.org/obo/DIDEO_00000041 Drug Ontology Identifier: http://purl.obolibrary.org/obo/CHEBI_61049 Causal Relation Ontology Identifier: http://purl.obolibrary.org/obo/RO_0002610 Adverse Event Ontology Identifier: http://purl.obolibrary.org/obo/MONDO_0002492\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "The Natural Product curcumin directly negatively regulates quantity of the Enzyme or Transporter cytochrome P450 3A4 (human). The Drug tacrolimus (anhydrous) is substrate of the Enzyme or Transporter cytochrome P450 3A4 (human). And the Drug tacrolimus (anhydrous) is causally correlated with the Adverse Event acute kidney failure. Natural Product Ontology Identifier: http://napdi.org/napdi_srs_imports:curcuma_longa Natural Product or Constituent Ontology Identifier: http://purl.obolibrary.org/obo/CHEBI_3962 Process Ontology Identifier: http://purl.obolibrary.org/obo/RO_0011010 Enzyme or Transporter Ontology Identifier: http://purl.obolibrary.org/obo/PR_P08684 Process or Pathway Ontology Identifier: http://purl.obolibrary.org/obo/DIDEO_00000041 Drug Ontology Identifier: http://purl.obolibrary.org/obo/CHEBI_61049 Causal Relation Ontology Identifier: http://purl.obolibrary.org/obo/RO_0002610 Adverse Event Ontology Identifier: http://purl.obolibrary.org/obo/MONDO_0002492\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "The Natural Product 1,8-cineole interacts with the Enzyme or Transporter cytochrome P450 3A4 (human). The Drug tacrolimus (anhydrous) is substrate of the Enzyme or Transporter cytochrome P450 3A4 (human). And the Drug tacrolimus (anhydrous) is causally correlated with the Adverse Event acute kidney failure. Natural Product Ontology Identifier: http://napdi.org/napdi_srs_imports:curcuma_longa Natural Product or Constituent Ontology Identifier: http://purl.obolibrary.org/obo/CHEBI_27961 Process Ontology Identifier: http://purl.obolibrary.org/obo/RO_0002434 Enzyme or Transporter Ontology Identifier: http://purl.obolibrary.org/obo/PR_P08684 Process or Pathway Ontology Identifier: http://purl.obolibrary.org/obo/DIDEO_00000041 Drug Ontology Identifier: http://purl.obolibrary.org/obo/CHEBI_61049 Causal Relation Ontology Identifier: http://purl.obolibrary.org/obo/RO_0002610 Adverse Event Ontology Identifier: http://purl.obolibrary.org/obo/MONDO_0002492\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "Ginger Unnamed: 1 Unnamed: 2 Zingiber officinale Roscoe (Zingiberaceae) Synonym(s) and related species Gan Jiang Zingiber Monograph Interpretation Citation Anticoaguants Evidence from pharmacological studies suggests that ginger does not increase the anticoagulant effect of warfarin, neither does it alter coagulation or platelet aggregation on its own. However, two cases reports describe markedly raised INRs with phenprocoumon and warfarin, which were associated with eating dried ginger and drinking ginger tea. A prospective, longitudinal study also reports of an increased risk of self-reported bleeding events in patients taking warfarin and ginger. Jiang X, Williams KM, Liauw WS, Ammit AJ, Roufogalis BD, Duke CC, Day RO, LcLachlan AJ. Effect of ginkgo and ginger on the pharmacokinetics and pharmacodynamics of warfarin in healthy subjects. Br J Clin Pharmacol (2005) 59, 425-32. Kruth P, Brosi E, Fux R, Morike K, Gleiter CH. Ginger-associated overanticoagulation by phenprocoumon. Ann Pharmacother (2004) 38, 257-60. Lesho EP, Saullo L, Udvari-Nagy S. A 76-year-old woman with erratic anticoagulation. Cleve Clin J Med (2004) 71, 651-6. Shalansky S, Lynd L, Richardson K, Ingaszewski A, Kerr C. Risk of warfarin-related bleeding events and supratherapeutic international normalized ratios associated with complementary and alternative medicine: a longitudinal analysis. Pharmacotherapy (2007) 27, 1237-47. Argento A, Tiraferri E, Marzaloni M. Anticoagulanti orali e piante medicinali. Una interazione emergente. Ann Ital Med Int (2000) 15, 139-43. Braun L. Herb-drug interaction guide. Aust Fam Physician (2001) 30, 473-6. Vacs LPJ, Chyka PA. Interactions of warfarin with garlic, ginger, ginkgo, or ginseng: nature of the evidence. Ann Pharmacother (2000) 34, 1478-82. Young H-Y, Liao J-C, Chang Y-S, Luo Y-L, Lu M-C, Peng W-H. Synergistic effect of ginger and nifedipine on human platelet aggregation: a study in hypertensive patients and normal volenteers. Am J Chin Med (2006) 34, 545-51. Caffeine For mention that sho-saiko-to (of which ginger is one of 7 constituents) onoy slightly reduced the metabolism of caffeine in one study, see Bupleurum + Caffeine, page 99. Carbamazepine For mention that saiko-ka-ryukotsu-borei-to and sho-saiko-to (of which ginger is one of a number of constituents) did not affect the pharmacokinetics of carbamazepine in animal studies, see Bupleurum + Carbamazepine, page 99. Food Not interactions found. Ginger is extensively used as a food ingredient. Herbal medicines No interactions found. Isoiazid For details of an animal study to investigate a possible interaction between isoniazid and Trikatu, an Ayurvedic medicine containing ginger, black pepper and long pepper, see Pepper + Isoniazid, page 375. Nifedipine A small study found that antiplatelet effects for ginger were synergistic with those nifedipine, but any effect needs confirmation. Young H-Y, Laio J-C, Chang Y-S, Luo Y-L, Lu M-C, Peng W-H. Synergistic effect of ginger and nifedipine on human platelet aggregation: a study in hypertensive patients and normal volunteers. Am J Chin Med (2006) 34, 545-51. Vaes LPJ, Chyka PA. Interactions of warfarin with garlic, ginger, ginkgo, or ginseng: nature of the evidence. Ann Pharmacother (2000) 34, 1478-82. NSAIDs For details of an animal study to investigate a possibe interaction between diclofenac and Trikatu, an Ayurvedic medicine containing ginger, black pepper and long pepper, see Pepper + NSAIDs page 376\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd654457-d149-4ff9-9721-9d0fa1a7e446",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reorder documents and merger into one context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b6dd0296-47e5-471f-a3d7-8a3eb7ca514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_transformers import (\n",
    "    LongContextReorder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "050bee81-4c6b-4cf2-8c96-c8457f1bee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "reordering = LongContextReorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "065aa4bb-8d99-4e2d-9af6-ef3e0b0a9001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['What mechanisms might explain the interaction between cranberry products and Warfarin that can lead to an increase in INR levels?', 'How do cranberry products interact with Warfarin, and what are the potential pathways that could result in elevated INR?', 'Can you elaborate on the possible ways in which cranberry products could interact with Warfarin to cause an increase in INR values?']\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['What mechanisms could explain the interaction between Green Tea products and Simvastatin that might lead to Statin intolerance?', 'How does the consumption of Green Tea potentially affect the efficacy and tolerance of Simvastatin in patients?', 'In what ways might Green Tea products influence the interaction with Simvastatin, potentially causing intolerance to Statins?']\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['What specific mechanisms might lead to interactions between grapefruit products and Nifedipine that could result in hypotension?', 'Can you explain how grapefruit products may interact with Nifedipine to potentially induce hypotension, and what mechanisms are involved?', 'What are the possible biological mechanisms behind the interaction of grapefruit products and Nifedipine that might lead to a decrease in blood pressure?']\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['What are the ways in which Grapefruit products might interact with Amlodipine to lead to low blood pressure?', 'Could you explain the mechanisms behind the interaction of Amlodipine and Grapefruit products that could result in hypotension?', 'What specific factors contribute to the interaction between Grapefruit and Amlodipine that may lead to a decrease in blood pressure?']\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['What are the possible ways in which Turmeric products might interact with Tacrolimus to lead to kidney damage?', 'Can you explain the mechanisms by which Turmeric could potentially affect Tacrolimus and result in nephrotoxicity?', 'How might the use of Turmeric products influence the safety and effectiveness of Tacrolimus, particularly regarding kidney health?']\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['What are the possible ways in which Turmeric products might interact with Tacrolimus to lead to neurotoxicity?', 'Can you explain the various mechanisms through which Turmeric could affect Tacrolimus and potentially result in neurotoxic effects?', 'What are the different mechanisms responsible for the interaction between Turmeric and Tacrolimus that could contribute to neurotoxicity?']\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['What mechanisms might lead to an interaction between Ginger products and Tacrolimus that could result in nephrotoxicity?', 'How do Ginger products potentially interact with Tacrolimus to induce nephrotoxicity, and what are the underlying mechanisms?', 'Can you explain the potential pathways through which Ginger products might interact with Tacrolimus and contribute to nephrotoxic effects?']\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['What are the possible ways in which Ginger products might interact with Tacrolimus to lead to neurotoxic effects?  ', 'Can you explain the mechanisms through which Ginger products could potentially affect Tacrolimus and result in neurotoxicity?  ', 'What interactions between Ginger products and Tacrolimus could contribute to neurotoxicity, and what are the underlying mechanisms?']\n"
     ]
    }
   ],
   "source": [
    "contexts = []\n",
    "for query in queries:\n",
    "    compressed_docs = compression_retriever.invoke(query.text)\n",
    "    reordered_docs = reordering.transform_documents(compressed_docs)\n",
    "    contexts.append('\\n\\n-----\\n\\n'.join(map(lambda x: x.page_content, reordered_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb72bc0-7853-49c7-baff-13a34bd9da6f",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a79c33c-bad3-48df-943b-6c9232e60ac5",
   "metadata": {},
   "source": [
    "# Reload context promps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7be22dc-805c-4739-8f50-c59e4a285739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "56d8ac95-c7de-47a4-af67-d0957838c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./contexts.pkl', 'wb') as out_file:\n",
    "#     pickle.dump(contexts, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c810d98-ecf5-4711-bf76-09f71d6c4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e5377bd-3a22-452a-a9a1-3a1c174064e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./contexts.pkl', 'rb') as in_file:\n",
    "    contexts = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e46fb9-69df-4db5-93ca-284c06815a64",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfa5302-6a4c-4d2c-bdff-0119d409ce50",
   "metadata": {},
   "source": [
    "# Results collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "255e3710-78a7-43b4-b580-d197ba6927d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = './Results/Rag-Results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a27aa-f5b8-48fb-b5e6-bc2bda12f397",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d5f4a2-0b6f-4fb7-9dc9-e0019a4d656d",
   "metadata": {},
   "source": [
    "# Baseline LLAMA 3.1 LLM Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "55e3de5e-d52e-476c-bee5-a1f562bda301",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9e38d35-286d-4f3e-b820-bf9b1c2f727a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348c23a5f0044a26ae9e6486bd2a003d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee1e91c60a8464cb508e0f3d729c99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model_id,\n",
    "    torch_dtype =dtype,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c0574f0-242b-4f61-ab85-3a34014e9982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''.join(['\\n\\n', context_header, context_instruction, contexts[I], '\\n\\n', query_header, queries[i].text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c2a3bef9-90ff-4ce4-9d8a-255994ecb6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(queries)):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": ''.join(['\\n\\n', context_header, context_instruction, contexts[i], '\\n\\n', query_header, queries[i].text])\n",
    "        },\n",
    "    ]\n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=3500,\n",
    "        temperature=1.0\n",
    "    )\n",
    "    with open(f'{results_dir}llama/llama_3.1_rag_({mappings.loc[i].NP},{mappings.loc[i].Drug},{mappings.loc[i].AE}).md', 'w') as f:\n",
    "        f.write('# Prompts to LLM:\\n\\n')\n",
    "        f.write(messages[0]['content'])\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(messages[1]['content'])\n",
    "        f.write('\\n\\n-------\\n\\n')\n",
    "        f.write('# Response from LLM:\\n\\n')\n",
    "        f.write(str(outputs[0][\"generated_text\"][-1][\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b506640-c12d-4c1e-8e18-3f1ef9834157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(outputs[0][\"generated_text\"][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d43144-1ecf-4fac-8bfb-17c9e45f5e22",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0080b7-0f2c-43c2-b473-5cb2268a943a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Baseline GEMMA 2 LLM Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7feb3727-d240-4db8-8949-df49b3671cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/gemma-2-9b-it\"\n",
    "dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7109d867-098b-4997-8391-2acc200107c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e89c473c3834dd5b411a9360a8b0578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model_id,\n",
    "    torch_dtype =dtype,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3b73b4b-b25e-4d9c-a63d-e7852462a048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (8192). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(queries)):\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": instruction_header + prompt + '\\n\\n' + context_header + context_instruction + contexts[i] + '\\n\\n' + query_header + queries[i].to_string()\n",
    "    }]\n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=3500,\n",
    "        temperature=1.0\n",
    "    )\n",
    "    with open(f'{results_dir}gemma/gemma_2_baseline_({mappings.loc[i].NP},{mappings.loc[i].Drug},{mappings.loc[i].AE}).md', 'w') as f:\n",
    "        f.write('# Prompts to LLM:\\n\\n')\n",
    "        f.write(messages[0]['content'])\n",
    "        f.write('\\n\\n-------\\n\\n')\n",
    "        f.write('# Response from LLM:\\n\\n')\n",
    "        f.write(str(outputs[0][\"generated_text\"][-1][\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fee44f42-5ef4-48fc-8464-92fa3767727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(outputs[0][\"generated_text\"][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f25b1c-1734-46bb-b586-905a1fef1824",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dfe9bd-1d81-4551-9567-0be61b3851ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Baseline GPT4o-mini LLM Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77ee5c3f-247c-42ef-807c-a7b585027551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c4075b5-bcda-49da-8348-f16d77b1c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "#     os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a897e81-cbb1-4f63-85e8-70692b20650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_PERSONAL_API_KEY\", default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5203c1a-7914-4644-ac3c-07218a1d6815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8307f281-7483-40b0-b779-2447935fed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1.0,\n",
    "    max_tokens=3500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5638e273-7288-4623-9874-2a252dfba768",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(queries)):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": ''.join(['\\n\\n', context_header, context_instruction, contexts[i], '\\n\\n', query_header, queries[i].text])\n",
    "        },\n",
    "    ]\n",
    "    outputs = llm.invoke(messages)\n",
    "    with open(f'{results_dir}gpt/gpt4o-mini_baseline_({mappings.loc[i].NP},{mappings.loc[i].Drug},{mappings.loc[i].AE}).md', 'w') as f:\n",
    "        f.write('# Prompts to LLM:\\n\\n')\n",
    "        f.write(messages[0]['content'])\n",
    "        f.write(\"\\n\")\n",
    "        f.write(messages[1]['content'])\n",
    "        f.write('\\n\\n-------\\n\\n')\n",
    "        f.write('# Response from LLM:\\n\\n')\n",
    "        f.write(str(outputs.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c14a2a-8cfb-4761-a1bf-531c3843ec6f",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a427b2c-004f-433d-8cdc-b50c098e23b8",
   "metadata": {},
   "source": [
    "# Baseline DeciLM LLM Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8937b4c9-5a15-41fe-9fb3-3e410c3a861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Deci/DeciLM-7B-instruct\"\n",
    "dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50c73fa3-b6fa-46e8-a94e-7f14588cf1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b4e825da5942a8a9989c36e602ab9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model_id,\n",
    "    torch_dtype =dtype,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebb822e6-7f06-46c5-8bbc-2d52ee352267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/ihome/crc/install/pytorch/2.0.1/python3.10/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (8192). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(queries)):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": ''.join([instruction_header, prompt])\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": ''.join(['\\n\\n', context_header, context_instruction, contexts[i], '\\n\\n', query_header, queries[i].text])\n",
    "        },\n",
    "    ]\n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=3500,\n",
    "        temperature=1.0\n",
    "    )\n",
    "    with open(f'{results_dir}deci/deci_baseline_({mappings.loc[i].NP},{mappings.loc[i].Drug},{mappings.loc[i].AE}).md', 'w') as f:\n",
    "        f.write('# Prompts to LLM:\\n\\n')\n",
    "        f.write(messages[0]['content'])\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(messages[1]['content'])\n",
    "        f.write('\\n\\n-------\\n\\n')\n",
    "        f.write('# Response from LLM:\\n\\n')\n",
    "        f.write(str(outputs[0][\"generated_text\"][-1][\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d365642a-4af5-4ee1-8142-51e0de163cb5",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03106469-854c-4e31-9487-13604bf77f31",
   "metadata": {},
   "source": [
    "# Baseline Mistral LLM Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a8521a6-9636-45cd-a76a-c1aa97e0a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fe25617-a30f-4e6e-a4a4-7d84091caf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7307799137428582d1adfaae9e232f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model_id,\n",
    "    torch_dtype =dtype,\n",
    "    device_map=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "755b77fe-0f51-4fd2-b870-b64a3b64e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(''.join([instruction_header, prompt,'\\n\\n', query_header, queries[0].text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "333c27bf-b084-4018-9241-8207396a0c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(queries)):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": ''.join([instruction_header, prompt])\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": ''.join(['\\n\\n', context_header, context_instruction, contexts[i], '\\n\\n', query_header, queries[i].text])\n",
    "        },\n",
    "    ]\n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=3500,\n",
    "        temperature=1.0\n",
    "    )\n",
    "    with open(f'{results_dir}mistral/mistral_rag_({mappings.loc[i].NP},{mappings.loc[i].Drug},{mappings.loc[i].AE}).md', 'w') as f:\n",
    "        f.write('# Prompts to LLM:\\n\\n')\n",
    "        f.write(messages[0]['content'])\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(messages[1]['content'])\n",
    "        f.write('\\n\\n-------\\n\\n')\n",
    "        f.write('# Response from LLM:\\n\\n')\n",
    "        f.write(str(outputs[0][\"generated_text\"][-1][\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9cf05-5be9-40db-aba3-3fedc129c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(outputs[0][\"generated_text\"][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec2a02-a0fb-4a9b-a261-54637e56b1de",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69830c59-d06e-4797-aaf5-79cf733578b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
